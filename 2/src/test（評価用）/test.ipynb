{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teraoka_r\\workspace\\development\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import mne\n",
    "from pymatreader import read_mat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from model import OneEncoderNet, TwoEncoderNet, TemporalNet, CWT2DCNN, MyPipeline\n",
    "\n",
    "data_dir = '../../data/test'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "CROP_LEN_ = 250\n",
    "\n",
    "label_dict = {\n",
    "    0: 'frontside_kickturn',\n",
    "    1: 'backside_kickturn',\n",
    "    2: 'pumping'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir):\n",
    "    data_dict = {}\n",
    "\n",
    "    for mat_data in glob.glob(f'{data_dir}/*.mat'):\n",
    "        subject = mat_data.split('\\\\')[-1].split('.')[0]\n",
    "        data = read_mat(mat_data)\n",
    "        data_dict[subject] = data['data']\n",
    "\n",
    "    ch_names = [c.replace(' ', '') for c in data['ch_labels']]\n",
    "    diff_list = [\n",
    "        #横方向\n",
    "        'F3_F4',\n",
    "        'FCz_FC1', 'FCz_FC2', 'FCz_FC3', 'FCz_FC4', 'FCz_FC5', 'FCz_FC6', 'FC1_FC2', 'FC3_FC4', 'FC5_FC6',\n",
    "        'Cz_C1', 'Cz_C2', 'Cz_C3', 'Cz_C4', 'Cz_C5', 'Cz_C6', 'C1_C2', 'C3_C4', 'C5_C6',\n",
    "        'CPz_CP1', 'CPz_CP2', 'CPz_CP3', 'CPz_CP4', 'CPz_CP5', 'CPz_CP6', 'CP1_CP2', 'CP3_CP4', 'CP5_CP6',\n",
    "        'P3_P4',\n",
    "        #縦方向\n",
    "        'Cz_FCz', 'C1_FC1', 'C2_FC2', 'C3_FC3', 'C4_FC4', 'C5_FC5', 'C6_FC6',\n",
    "        'Cz_CPz', 'C1_CP1', 'C2_CP2', 'C3_CP3', 'C4_CP4', 'C5_CP5', 'C6_CP6',\n",
    "        'FCz_CPz', 'FC1_CP1', 'FC2_CP2', 'FC3_CP3', 'FC4_CP4', 'FC5_CP5', 'FC6_CP6',\n",
    "    ]\n",
    "\n",
    "    use_ch = []\n",
    "    for item in diff_list:\n",
    "        ch1 = item.split('_')[0]\n",
    "        ch2 = item.split('_')[1]\n",
    "        use_ch.append(ch1)\n",
    "        use_ch.append(ch2)\n",
    "\n",
    "    use_ch = list(set(use_ch))\n",
    "    use_ch_dict = {ch_names[idx]:idx for idx in range(len(ch_names)) if ch_names[idx] in use_ch}\n",
    "    \n",
    "    return data_dict, diff_list, use_ch_dict\n",
    "\n",
    "\n",
    "class SkateDataset(Dataset):\n",
    "    def __init__(self, fold, data, diff_list, use_ch_dict):\n",
    "        self.diff_list = diff_list\n",
    "        self.use_ch_dict = use_ch_dict\n",
    "        \n",
    "        self.iqr = np.load(f'../../data/scaler/iqr{fold}.npy', allow_pickle=True)\n",
    "        self.median = np.load(f'../../data/scaler/median{fold}.npy', allow_pickle=True)\n",
    "        self.iqr = self.iqr.reshape(72, 1)\n",
    "        self.median = self.median.reshape(72, 1)\n",
    "\n",
    "        eeg_signals = []\n",
    "        for data_ in data:\n",
    "            data_ = (data_ - self.median) / self.iqr\n",
    "            eeg_signal = []\n",
    "            for ch_num, channels in enumerate(self.diff_list):\n",
    "                ch1_name = channels.split('_')[0]\n",
    "                ch2_name = channels.split('_')[1]\n",
    "                ch1 = data_[self.use_ch_dict[ch1_name]]\n",
    "                ch2 = data_[self.use_ch_dict[ch2_name]]\n",
    "                signal = ch1 - ch2\n",
    "                eeg_signal.append(signal)\n",
    "            eeg_signal = np.stack(eeg_signal)\n",
    "            eeg_signals.append(eeg_signal)\n",
    "        self.eeg_signals = np.stack(eeg_signals)\n",
    "        self.eeg_signals_72 = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_signals.shape[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.eeg_signals[index]\n",
    "        data_72 = self.eeg_signals_72[index]\n",
    "        \n",
    "        return data, data_72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, diff_list, use_ch_dict = get_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(fold):\n",
    "    model_list_eeg = []\n",
    "    model = OneEncoderNet()\n",
    "    load_weights = torch.load(f'../1st_train_1D/one-encoder/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "    model = TwoEncoderNet()\n",
    "    load_weights = torch.load(f'../1st_train_1D/two-encoder/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='tf_efficientnet_b0.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/tf_efficientnet_b0/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='tf_efficientnet_b3.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/tf_efficientnet_b3/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='efficientvit_b1.r256_in1k')\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/efficientvit_b1/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='tf_efficientnetv2_b0.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/tf_efficientnetv2_b0/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_eeg.append(model)\n",
    "\n",
    "\n",
    "    model_list_cwt = []\n",
    "    model = CWT2DCNN(model_name='tf_efficientnet_b0.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_2D/tf_efficientnet_b0/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_cwt.append(model)\n",
    "\n",
    "    model = CWT2DCNN(model_name='tf_efficientnet_b3.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_2D/tf_efficientnet_b3/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_cwt.append(model)\n",
    "\n",
    "    model = CWT2DCNN(model_name='efficientvit_b0.r224_in1k')\n",
    "    load_weights = torch.load(f'../1st_train_2D/efficientvit_b0/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_cwt.append(model)\n",
    "\n",
    "    model = CWT2DCNN(model_name='efficientvit_b3.r224_in1k')\n",
    "    load_weights = torch.load(f'../1st_train_2D/efficientvit_b3/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_cwt.append(model)\n",
    "\n",
    "    model = CWT2DCNN(model_name='tf_efficientnetv2_b0.in1k')\n",
    "    load_weights = torch.load(f'../1st_train_2D/tf_efficientnetv2_b0/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_cwt.append(model)\n",
    "\n",
    "\n",
    "    model_list_72 = []\n",
    "    model = OneEncoderNet(in_channels=72)\n",
    "    load_weights = torch.load(f'../1st_train_1D/one-encoder_72/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_72.append(model)\n",
    "\n",
    "    model = TwoEncoderNet(in_channels=72)\n",
    "    load_weights = torch.load(f'../1st_train_1D/two-encoder_72/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_72.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='tf_efficientnet_b0.in1k', in_channels=72)\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/tf_efficientnet_b0_72/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_72.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='tf_efficientnet_b3.in1k', in_channels=72)\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/tf_efficientnet_b3_72/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_72.append(model)\n",
    "\n",
    "    model = TemporalNet(model_name='efficientvit_b1.r256_in1k', in_channels=72)\n",
    "    load_weights = torch.load(f'../1st_train_1Dtemporal/efficientvit_b1_72/model/model{fold}.pth', map_location=device, weights_only=True)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model = model.eval().to(device)\n",
    "    model_list_72.append(model)\n",
    "\n",
    "    model_lists = []\n",
    "    model_lists.append(model_list_eeg)\n",
    "    model_lists.append(model_list_cwt)\n",
    "    model_lists.append(model_list_72)\n",
    "\n",
    "    return model_lists\n",
    "\n",
    "\n",
    "def get_lgb_model(fold):\n",
    "    model_list_eeg = []\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1D/one-encoder/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1D/two-encoder/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/tf_efficientnet_b0/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/tf_efficientnet_b3/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/efficientvit_b1/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/tf_efficientnetv2_b0/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_eeg.append(temp)\n",
    "\n",
    "    \n",
    "    model_list_cwt = []\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_2D/tf_efficientnet_b0/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_cwt.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_2D/tf_efficientnet_b3/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_cwt.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_2D/efficientvit_b0/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_cwt.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_2D/efficientvit_b3/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_cwt.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_2D/tf_efficientnetv2_b0/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_cwt.append(temp)\n",
    "\n",
    "\n",
    "    model_list_72 = []\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1D/one-encoder_72/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_72.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1D/two-encoder_72/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_72.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/tf_efficientnet_b0_72/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_72.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/tf_efficientnet_b3_72/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_72.append(temp)\n",
    "\n",
    "    temp = []\n",
    "    for fold_ in range(3):\n",
    "        model = load(open(f'../1st_train_1Dtemporal/efficientvit_b1_72/lgb_model/lgb_fold{fold}_{fold_}', 'rb'))\n",
    "        temp.append(model)\n",
    "    model_list_72.append(temp)\n",
    "\n",
    "    model_lists = []\n",
    "    model_lists.append(model_list_eeg)\n",
    "    model_lists.append(model_list_cwt)\n",
    "    model_lists.append(model_list_72)\n",
    "\n",
    "    return model_lists\n",
    "\n",
    "\n",
    "def get_weight():\n",
    "    weight_list_eeg = []\n",
    "    weight = np.load(f'../1st_train_1D/one-encoder/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1D/two-encoder/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/tf_efficientnet_b0/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/tf_efficientnet_b3/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/efficientvit_b1/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/tf_efficientnetv2_b0/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_eeg.append(weight)\n",
    "\n",
    "    \n",
    "    weight_list_cwt = []\n",
    "    weight = np.load(f'../1st_train_2D/tf_efficientnet_b0/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_cwt.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_2D/tf_efficientnet_b3/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_cwt.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_2D/efficientvit_b0/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_cwt.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_2D/efficientvit_b3/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_cwt.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_2D/tf_efficientnetv2_b0/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_cwt.append(weight)\n",
    "\n",
    "\n",
    "    weight_list_72 = []\n",
    "    weight = np.load(f'../1st_train_1D/one-encoder_72/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_72.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1D/two-encoder_72/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_72.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/tf_efficientnet_b0_72/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_72.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/tf_efficientnet_b3_72/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_72.append(weight)\n",
    "\n",
    "    weight = np.load(f'../1st_train_1Dtemporal/efficientvit_b1_72/output/weight.npy', allow_pickle=True)\n",
    "    weight_list_72.append(weight)\n",
    "\n",
    "    weight_lists = []\n",
    "    weight_lists.append(weight_list_eeg)\n",
    "    weight_lists.append(weight_list_cwt)\n",
    "    weight_lists.append(weight_list_72)\n",
    "\n",
    "    return weight_lists\n",
    "\n",
    "\n",
    "def predict(X, X_72, nn_model_lists, lgb_model_lists, weight_lists, fold):\n",
    "    preds = []\n",
    "    pipeline = MyPipeline(samplerate=500, lowcut=1, highcut=180, wavelet_width=1, n_scales=16, stride=1).to(device)\n",
    "    for num, (nn_model_list, lgb_model_list, weight_list) in enumerate(zip(nn_model_lists, lgb_model_lists, weight_lists)):\n",
    "        for nn_model, lgb_model, weight in zip(nn_model_list, lgb_model_list, weight_list):\n",
    "            with torch.no_grad():\n",
    "                if num == 2:\n",
    "                    y_pred, features = nn_model(X_72)\n",
    "                elif num == 1:\n",
    "                    y_pred, features = nn_model(pipeline(X))\n",
    "                else:\n",
    "                    y_pred, features = nn_model(X)\n",
    "            nn_pred = nn.functional.softmax(y_pred, dim=1).detach().cpu().numpy()\n",
    "\n",
    "            lgb_pred = []\n",
    "            for model in lgb_model:\n",
    "                proba = model.predict_proba(features.detach().cpu().numpy(), num_iteration=model.best_iteration_)\n",
    "                lgb_pred.append(proba)\n",
    "            lgb_pred = np.mean(np.stack(lgb_pred, axis=0), axis=0)\n",
    "\n",
    "            y_pred = weight[fold] * nn_pred + (1 - weight[fold]) * lgb_pred\n",
    "\n",
    "            preds.append(y_pred)\n",
    "    preds = torch.from_numpy(np.stack(preds, axis=0))\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = ['subject0', 'subject1', 'subject2', 'subject3', 'subject4']\n",
    "weight_lists = get_weight()\n",
    "predict_list = []\n",
    "for target in target_list:\n",
    "    print(f'calculating -> {target}')\n",
    "    data = data_dict[target]\n",
    "    preds = []\n",
    "    for fold in range(3):\n",
    "        dataset = SkateDataset(fold, data, diff_list, use_ch_dict)\n",
    "        X = dataset.eeg_signals\n",
    "        X = torch.from_numpy(X).to(device).float()\n",
    "        X_72 = dataset.eeg_signals_72\n",
    "        X_72 = torch.from_numpy(X_72).to(device).float()\n",
    "\n",
    "        nn_model_lists = get_model(fold)\n",
    "        lgb_model_lists = get_lgb_model(fold)\n",
    "        y_pred = predict(X, X_72, nn_model_lists, lgb_model_lists, weight_lists, fold)\n",
    "        preds.append(y_pred)\n",
    "    preds = torch.argmax(torch.mean(torch.cat(preds, dim=0), dim=0), dim=1)\n",
    "    for i, pred in enumerate(preds):\n",
    "        if i < 10:\n",
    "            number = f'00{i}'\n",
    "        elif i < 100:\n",
    "            number = f'0{i}'\n",
    "        else:\n",
    "            number = str(i)\n",
    "        target_name = f'{target}_{number}'\n",
    "        label = label_dict[pred.item()]\n",
    "        predict_list.append([target_name, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predict_list)\n",
    "df.to_csv('submit.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
